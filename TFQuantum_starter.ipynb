{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with [TensorFlow Quantum](https://www.tensorflow.org/quantum)\n",
    "\n",
    "In this notebook you will build your first hybrid quantum classical model with \n",
    "[Cirq](https://cirq.readthedocs.io/en/stable/) and TensorFlow Quantum (TFQ). We will build a very simple model to do\n",
    "binary classification in this notebook. You will then use Keras to create a wrapper for the model and simulate it to\n",
    "train and evluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: This notebook is designed to be run in Google Colab if you want to run it locally or on a Jupyter notebook you \n",
    "would skip the code cells with the `Colab only` comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install TensorFlow Quantum (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab only\n",
    "pip install -q tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab only\n",
    "pip install -q tensorflow-quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirq\n",
    "import random\n",
    "import numpy as np\n",
    "import sympy\n",
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place a qubit on the grid\n",
    "\n",
    "You will then place a qubit on thee grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qubit = cirq.GridQubit(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare quantum data\n",
    "\n",
    "The first thing you would do is set up the labels and parameters for preparation of the quantum data. For simplicity\n",
    "here we have included just 2 data points `a` and `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_labels = np.array([[1, 0], [0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randonly rotate `x` and `z` axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = np.random.uniform(0, 2 * np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the quantum Circuit\n",
    "\n",
    "You will now build the quantum circuit and also convert it into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cirq.Circuit(cirq.ry(angle)(qubit))\n",
    "b = cirq.Circuit(cirq.ry(angle + np.pi / 2)(qubit))\n",
    "quantum_data = tfq.convert_to_tensor([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"204.7082421875\" height=\"50.0\"><line x1=\"34.7588671875\" x2=\"174.7082421875\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 0): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"75.1905078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"117.11298828125001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">Ry(1.41π)</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f29a5935a50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"204.7082421875\" height=\"50.0\"><line x1=\"34.7588671875\" x2=\"174.7082421875\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">(0, 0): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"75.1905078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"117.11298828125001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\">Ry(1.41π)</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f2965655e90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the hybrid model\n",
    "\n",
    "This section also shows the interoperatability between TensorFlow and Cirq. With the TFQ PQC layer you can easily\n",
    "embed your quantum part of the model within a standard classical Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_data_input = tf.keras.Input(shape = (), dtype = tf.dtypes.string)\n",
    "theta = sympy.Symbol(\"theta\")\n",
    "q_model = cirq.Circuit(cirq.ry(theta)(qubit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "expectation = tfq.layers.PQC(q_model, cirq.Z(qubit))\n",
    "expectation_output = expectation(q_data_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.layers.Dense(2, activation = tf.keras.activations.softmax)\n",
    "classifier_output = classifier(expectation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now define the optimizer and loss functions for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = q_data_input, \n",
    "                       outputs = classifier_output)\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1), \n",
    "              loss = tf.keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traaining the model\n",
    "\n",
    "Training the model is just like training any other Keras model and is made easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples\n",
      "Epoch 1/250\n",
      "2/2 [==============================] - 2s 1s/sample - loss: 0.8917\n",
      "Epoch 2/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.8091\n",
      "Epoch 3/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.7424\n",
      "Epoch 4/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.6847\n",
      "Epoch 5/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.6361\n",
      "Epoch 6/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.5919\n",
      "Epoch 7/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.5472\n",
      "Epoch 8/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.5011\n",
      "Epoch 9/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.4544\n",
      "Epoch 10/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.4079\n",
      "Epoch 11/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.3624\n",
      "Epoch 12/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.3193\n",
      "Epoch 13/250\n",
      "2/2 [==============================] - 0s 5ms/sample - loss: 0.2801\n",
      "Epoch 14/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.2455\n",
      "Epoch 15/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.2159\n",
      "Epoch 16/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.1910\n",
      "Epoch 17/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.1699\n",
      "Epoch 18/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.1521\n",
      "Epoch 19/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.1368\n",
      "Epoch 20/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.1236\n",
      "Epoch 21/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.1122\n",
      "Epoch 22/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.1025\n",
      "Epoch 23/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0942\n",
      "Epoch 24/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0869\n",
      "Epoch 25/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0804\n",
      "Epoch 26/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0746\n",
      "Epoch 27/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0693\n",
      "Epoch 28/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0645\n",
      "Epoch 29/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0601\n",
      "Epoch 30/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0561\n",
      "Epoch 31/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0525\n",
      "Epoch 32/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0492\n",
      "Epoch 33/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0463\n",
      "Epoch 34/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0436\n",
      "Epoch 35/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0411\n",
      "Epoch 36/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0389\n",
      "Epoch 37/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0368\n",
      "Epoch 38/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0349\n",
      "Epoch 39/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0332\n",
      "Epoch 40/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0317\n",
      "Epoch 41/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0303\n",
      "Epoch 42/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0290\n",
      "Epoch 43/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0278\n",
      "Epoch 44/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0268\n",
      "Epoch 45/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0258\n",
      "Epoch 46/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0248\n",
      "Epoch 47/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0240\n",
      "Epoch 48/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0232\n",
      "Epoch 49/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0224\n",
      "Epoch 50/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0218\n",
      "Epoch 51/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0211\n",
      "Epoch 52/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0205\n",
      "Epoch 53/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0200\n",
      "Epoch 54/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0195\n",
      "Epoch 55/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0190\n",
      "Epoch 56/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0185\n",
      "Epoch 57/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0181\n",
      "Epoch 58/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0177\n",
      "Epoch 59/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0173\n",
      "Epoch 60/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0169\n",
      "Epoch 61/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0166\n",
      "Epoch 62/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0163\n",
      "Epoch 63/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0159\n",
      "Epoch 64/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0156\n",
      "Epoch 65/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0154\n",
      "Epoch 66/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0151\n",
      "Epoch 67/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0148\n",
      "Epoch 68/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0146\n",
      "Epoch 69/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0143\n",
      "Epoch 70/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0141\n",
      "Epoch 71/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0139\n",
      "Epoch 72/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0136\n",
      "Epoch 73/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0134\n",
      "Epoch 74/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0132\n",
      "Epoch 75/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0130\n",
      "Epoch 76/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0128\n",
      "Epoch 77/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0126\n",
      "Epoch 78/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0125\n",
      "Epoch 79/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0123\n",
      "Epoch 80/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0121\n",
      "Epoch 81/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0120\n",
      "Epoch 82/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0118\n",
      "Epoch 83/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0116\n",
      "Epoch 84/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0115\n",
      "Epoch 85/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0113\n",
      "Epoch 86/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0112\n",
      "Epoch 87/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0110\n",
      "Epoch 88/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0109\n",
      "Epoch 89/250\n",
      "2/2 [==============================] - 0s 5ms/sample - loss: 0.0108\n",
      "Epoch 90/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0106\n",
      "Epoch 91/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0105\n",
      "Epoch 92/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0104\n",
      "Epoch 93/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0103\n",
      "Epoch 94/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0101\n",
      "Epoch 95/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0100\n",
      "Epoch 96/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0099\n",
      "Epoch 97/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0098\n",
      "Epoch 98/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0097\n",
      "Epoch 99/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0096\n",
      "Epoch 100/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0095\n",
      "Epoch 101/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0094\n",
      "Epoch 102/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0092\n",
      "Epoch 103/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0091\n",
      "Epoch 104/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0090\n",
      "Epoch 105/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0089\n",
      "Epoch 106/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0089\n",
      "Epoch 107/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0088\n",
      "Epoch 108/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0087\n",
      "Epoch 109/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0086\n",
      "Epoch 110/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0085\n",
      "Epoch 111/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0084\n",
      "Epoch 112/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0083\n",
      "Epoch 113/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0082\n",
      "Epoch 114/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0081\n",
      "Epoch 115/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0081\n",
      "Epoch 116/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0080\n",
      "Epoch 117/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0079\n",
      "Epoch 118/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0078\n",
      "Epoch 119/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0077\n",
      "Epoch 120/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0077\n",
      "Epoch 121/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0076\n",
      "Epoch 122/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0075\n",
      "Epoch 123/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0074\n",
      "Epoch 124/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0074\n",
      "Epoch 125/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0073\n",
      "Epoch 126/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 127/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0072\n",
      "Epoch 128/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0071\n",
      "Epoch 129/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0070\n",
      "Epoch 130/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0070\n",
      "Epoch 131/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0069\n",
      "Epoch 132/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0068\n",
      "Epoch 133/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0068\n",
      "Epoch 134/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0067\n",
      "Epoch 135/250\n",
      "2/2 [==============================] - 0s 5ms/sample - loss: 0.0067\n",
      "Epoch 136/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0066\n",
      "Epoch 137/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0065\n",
      "Epoch 138/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0065\n",
      "Epoch 139/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 140/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0064\n",
      "Epoch 141/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0063\n",
      "Epoch 142/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0063\n",
      "Epoch 143/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0062\n",
      "Epoch 144/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0062\n",
      "Epoch 145/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0061\n",
      "Epoch 146/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0061\n",
      "Epoch 147/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0060\n",
      "Epoch 148/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0060\n",
      "Epoch 149/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0059\n",
      "Epoch 150/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0059\n",
      "Epoch 151/250\n",
      "2/2 [==============================] - 0s 5ms/sample - loss: 0.0058\n",
      "Epoch 152/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0058\n",
      "Epoch 153/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0057\n",
      "Epoch 154/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0057\n",
      "Epoch 155/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0056\n",
      "Epoch 156/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0056\n",
      "Epoch 157/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0055\n",
      "Epoch 158/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0055\n",
      "Epoch 159/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0054\n",
      "Epoch 160/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0054\n",
      "Epoch 161/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0054\n",
      "Epoch 162/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0053\n",
      "Epoch 163/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0053\n",
      "Epoch 164/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0052\n",
      "Epoch 165/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0052\n",
      "Epoch 166/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0052\n",
      "Epoch 167/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0051\n",
      "Epoch 168/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0051\n",
      "Epoch 169/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0050\n",
      "Epoch 170/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0050\n",
      "Epoch 171/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0050\n",
      "Epoch 172/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0049\n",
      "Epoch 173/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0049\n",
      "Epoch 174/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0049\n",
      "Epoch 175/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0048\n",
      "Epoch 176/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0048\n",
      "Epoch 177/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0047\n",
      "Epoch 178/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0047\n",
      "Epoch 179/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0047\n",
      "Epoch 180/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0046\n",
      "Epoch 181/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0046\n",
      "Epoch 182/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0046\n",
      "Epoch 183/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0045\n",
      "Epoch 184/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0045\n",
      "Epoch 185/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0045\n",
      "Epoch 186/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0045\n",
      "Epoch 187/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0044\n",
      "Epoch 188/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0044\n",
      "Epoch 189/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0044\n",
      "Epoch 190/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0043\n",
      "Epoch 191/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0043\n",
      "Epoch 192/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0043\n",
      "Epoch 193/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0042\n",
      "Epoch 194/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0042\n",
      "Epoch 195/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0042\n",
      "Epoch 196/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0042\n",
      "Epoch 197/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0041\n",
      "Epoch 198/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0041\n",
      "Epoch 199/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0041\n",
      "Epoch 200/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0041\n",
      "Epoch 201/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0040\n",
      "Epoch 202/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0040\n",
      "Epoch 203/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0040\n",
      "Epoch 204/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0039\n",
      "Epoch 205/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 206/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0039\n",
      "Epoch 207/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0039\n",
      "Epoch 208/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0038\n",
      "Epoch 209/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0038\n",
      "Epoch 210/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0038\n",
      "Epoch 211/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0038\n",
      "Epoch 212/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0038\n",
      "Epoch 213/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0037\n",
      "Epoch 214/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0037\n",
      "Epoch 215/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0037\n",
      "Epoch 216/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0037\n",
      "Epoch 217/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0036\n",
      "Epoch 218/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0036\n",
      "Epoch 219/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0036\n",
      "Epoch 220/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0036\n",
      "Epoch 221/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0035\n",
      "Epoch 222/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 223/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0035\n",
      "Epoch 224/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0035\n",
      "Epoch 225/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0035\n",
      "Epoch 226/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0034\n",
      "Epoch 227/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0034\n",
      "Epoch 228/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0034\n",
      "Epoch 229/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0034\n",
      "Epoch 230/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0034\n",
      "Epoch 231/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0033\n",
      "Epoch 232/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0033\n",
      "Epoch 233/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0033\n",
      "Epoch 234/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0033\n",
      "Epoch 235/250\n",
      "2/2 [==============================] - 0s 4ms/sample - loss: 0.0033\n",
      "Epoch 236/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0032\n",
      "Epoch 237/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0032\n",
      "Epoch 238/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0032\n",
      "Epoch 239/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0032\n",
      "Epoch 240/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0032\n",
      "Epoch 241/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0032\n",
      "Epoch 242/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0031\n",
      "Epoch 243/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 244/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0031\n",
      "Epoch 245/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0031\n",
      "Epoch 246/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0031\n",
      "Epoch 247/250\n",
      "2/2 [==============================] - 0s 2ms/sample - loss: 0.0031\n",
      "Epoch 248/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0030\n",
      "Epoch 249/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0030\n",
      "Epoch 250/250\n",
      "2/2 [==============================] - 0s 3ms/sample - loss: 0.0030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = quantum_data, \n",
    "                    y = expected_labels, \n",
    "                    epochs = 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.uniform(-0.25, 0.25, 2)\n",
    "test_data = tfq.convert_to_tensor([\n",
    "    cirq.Circuit(cirq.ry(noise[0])(qubit)),\n",
    "    cirq.Circuit(cirq.ry(np.pi/2)(qubit)),    \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the below cell that our model does a good job with this data though it was very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.136258e-02, 9.486374e-01],\n",
       "       [9.992995e-01, 7.004250e-04]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
